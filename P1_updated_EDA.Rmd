---
title: "EDA for P1"
author: "Addison McGhee"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=F}
knitr::opts_chunk$set(echo = TRUE, message = F)
```


```{r, include=F}
library(AER)
library(caret)
library(e1071)
library(eeptools)
library(foreign)
library(gam)
library(ggrepel)
library(ggthemes)
library(gridExtra)
library(lubridate)
library(magrittr)
library(nnet)
library(pander)
library(pROC)
library(pscl)
library(randomForest)
library(rpart)
library(splines)
library(splines2)
library(splitstackshape)
library(tidyverse)
library(VGAM)
library(vcd)
options(digits = 3)
theme_update(plot.title = element_text(hjust = 0.5))
```

```{r}
injured = read.csv("all_injuries_clean.csv") # load data
```

```{r, include=F}
fix_nfl_names <- function(x){ #https://rdrr.io/github/papagorgio23/bettoR/src/R/fix_nfl_names.R
  x[grep("Arizona Cardinals", x, ignore.case=TRUE)] <- "ARI"
  
  x[grep("Atlanta Falcons", x, ignore.case=TRUE)] <- "ATL"

  x[grep("Baltimore Ravens", x, ignore.case=TRUE)] <- "BAL"

  x[grep("Buffalo Bills", x, ignore.case=TRUE)] <- "BUF"

  x[grep("Carolina Panthers", x, ignore.case=TRUE)] <- "CAR"

  x[grep("Chicago Bears", x, ignore.case=TRUE)] <- "CHI"

  x[grep("Cincinnati Bengals", x, ignore.case=TRUE)] <- "CIN"

  x[grep("Cleveland Browns", x, ignore.case=TRUE)] <- "CLE"

  x[grep("Dallas Cowboys", x, ignore.case=TRUE)] <- "DAL"

  x[grep("Denver Broncos", x, ignore.case=TRUE)] <- "DEN"

  x[grep("Detroit Lions", x, ignore.case=TRUE)] <- "DET"

  x[grep("Green Bay Packers", x, ignore.case=TRUE)] <- "GB"

  x[grep("Houston Texans", x, ignore.case=TRUE)] <- "HOU"

  x[grep("Indianapolis Colts", x, ignore.case=TRUE)] <- "IND"

  x[grep("Jacksonville Jaguars", x, ignore.case=TRUE)] <- "JAX"

  x[grep("Kansas City Chiefs", x, ignore.case=TRUE)] <- "KC"

  x[grep("Miami Dolphins", x, ignore.case=TRUE)] <- "MIA"

  x[grep("Minnesota Vikings", x, ignore.case=TRUE)] <- "MIN"

  x[grep("New England Patriots", x, ignore.case=TRUE)] <- "NE"

  x[grep("New Orleans Saints", x, ignore.case=TRUE)] <- "NO"

  x[grep("New York Jets", x, ignore.case=TRUE)] <- "NYJ"

  x[grep("New York Giants", x, ignore.case=TRUE)] <- "NYG"

  x[grep("Las Vegas Raiders", x, ignore.case=TRUE)] <- "OAK"

  x[grep("Philadelphia Eagles", x, ignore.case=TRUE)] <- "PHI"

  x[grep("Pittsburgh Steelers", x, ignore.case=TRUE)] <- "PIT"

  x[grep("Los Angeles Chargers", x, ignore.case=TRUE)] <- "LAC"

  x[grep("Los Angeles Rams", x, ignore.case=TRUE)] <- "LAR"

  x[grep("San Francisco 49ers", x, ignore.case=TRUE)] <- "SF"

  x[grep("Seattle Seahawks", x, ignore.case=TRUE)] <- "SEA"

  x[grep("Tampa Bay Buccaneers", x, ignore.case=TRUE)] <- "TB"

  x[grep("Tennessee Titans", x, ignore.case=TRUE)] <- "TEN"

  x[grep("Washington Redskins", x, ignore.case=TRUE)] <- "WAS"

  return(x)
}

age <- function(dob, age.day = today(), units = "years", floor = TRUE) {
    calc.age = interval(dob, age.day) / duration(num = 1, units = units)
    if (floor) return(as.integer(floor(calc.age)))
    return(calc.age)
}
```

&nbsp;

### Select columns
```{r}
injured = injured %>% 
  mutate(short_team_name = fix_nfl_names(full_team), injury = rep(1, nrow(injured))) %>%
  filter(head == 1 | shoulder == 1 | upper_torso == 1 | 
         lower_torso == 1 | arm == 1 | hand == 1 | 
         leg == 1 | foot == 1) %>% 
  select(name, short_team_name, full_team, team, year, injury)

```

&nbsp;

### Load demographic data
```{r}
players_dat = read.csv("all_player_demographic_clean.csv")

players = players_dat %>% 
  mutate(short_team_name = fix_nfl_names(full_team), 
         age = age(ymd(birthdate)), bmi = (weight_pounds / height_inches^2)*703) %>% 
  select(name, short_team_name, full_team, team, year, position_id, age, bmi, game_starter)

'filter(year == 2018) %>% 
            mutate(injury = as.factor(ifelse(is.na(injury_types), 0, 1)), # make binary injury variable
                   position_id = as.factor(position_id), # make position categorical
                   bmi = weight_pounds / height_inches^2, # make BMI variable
                   age = age(ymd(birthdate)) - 3) %>% # subtract 3 years to match age in 2018
            filter(position_id != "")'
```

&nbsp;

### Merge with injury data
```{r}
injuries = injured %>% left_join(players, by = c("name", "full_team", "short_team_name", "year", "team")) %>%
  filter(position_id != "") %>% 
  mutate(injury = factor(injury), position_id = factor(position_id))

players = players %>% left_join(injured, by = c("name", "full_team", "short_team_name", "year", "team")) %>% 
  mutate(injury = factor(ifelse(is.na(injury), 0, 1))) %>%
  filter(position_id != "") %>% 
  mutate(injury = factor(injury), position_id = factor(position_id))

```
 
&nbsp;

# P1

### Q1: Which positions are most at-risk for injuries? The table below contains descriptive statistics calculated for each position over multiple seasons (2009 - Present). 

```{r}
number_injury = injuries %>% 
  group_by(position_id, year) %>% 
  count()

number_injury %>% group_by(position_id) %>% 
  summarise(mean = mean(n), 
            sd = sd(n), 
            Q1 = quantile(n, probs = 0.25),
            median = median(n),
            Q3 = quantile(n, probs = 0.75)
  ) %>% 
  pander
```                                                   


```{r}             
number_injury %>% ggplot(aes(year, n, color = position_id)) +
                    geom_line() +
                    xlab("Year") +
                    ylab("# of Injuries") +
                    scale_color_discrete(name = "Position") +
                    ggtitle("Number of Injuries by Position (2009 - Present)")
```

&nbsp;

### Maybe a $\log_{10}$ transform could help
```{r}             
number_injury %>% ggplot(aes(year, n, color = position_id)) +
                    geom_line() +
                    xlab("Year") +
                    ylab("# of Injuries (log_10 scale)") +
                    scale_color_discrete(name = "Position") +
                    ggtitle("Number of Injuries (log_10 scale) by Position (2009 - Present)") +
                    scale_y_log10()
```

&nbsp;

### What about injuries per year? Is this uniformly distributed?
```{r}
injuries %>% ggplot(aes(year)) + 
              geom_bar() + 
              ylab("# of Injuries") +
              ggtitle("# of Injuries per Year")
```

&nbsp;

### We now will switch to our second analysis (Machine Learning)
* For the next analyses, we will only look at the **2018** season
* We will perform logistic regression, kNN, and random forest using the binary outcome `injury`. 
* Our predictors will be continuous bmi and the categorical variable `position_id`. 
* We will then compare the results of the different methods based on accuracy, sensitivity/specificity, and ROC/AUC.

&nbsp;

### Our first step is to check for missing data in our predictors and outcome
```{r}
players = players %>% 
  filter(year == 2018) %>% 
  mutate(age = age - 3) # subtract 3 years for 2018 age

apply(players %>% 
        select(injury, bmi, position_id, age), 2, 
      function(x) sum(is.na(x))) %>% pander
```

&nbsp;

**Fortunately, our covariates of interest do not have any missing values during the 2018 season.**

&nbsp;

### What is the distribution of injuries by position in 2018?

```{r}
players$position_id = 
  fct_relevel(players$position_id, c("DEF", "OL", "WR", "RB", "TE", "QB", "K", "P"))

players %>% 
  ggplot(aes(position_id, fill = injury)) +
    geom_bar(position = "dodge") +
    xlab("Position") +
    ylab("# of Players") +
    ggtitle("Injured Players by Position in 2018") +
    scale_fill_manual(name = "Injury", guide = guide_legend(reverse=TRUE), values = c("#619CFF", "#F8766D"))
  
```

&nbsp;

**The graph above is very useful for determining whether a logistic regression coefficient would likely be statistically significant. We are looking to see, for a given position, if there is a large discrepancy between the number of injured and non-injured players. If the number of players injured is much larger than the number of non-injured players, then we would expect that the odds of getting injured in this position is large. We would expect the opposite to be the case for a position where the number of non-injured players is much greater than the number of injured players.**

&nbsp;

### What is the distribution of BMI for the injured vs non-injured players?
```{r}
players %>% ggplot(aes(injury, bmi)) +
              geom_boxplot()
```

&nbsp;

**The absence of any significant difference between groups suggests that `bmi` will not be a significiant predictor in our Logistic model.**

&nbsp;

### What is the distribution of `injury` by `age` in 2018?
```{r}
injuries %>% filter(year == 2018) %>% 
             mutate(age = age - 3) %>% # subtract 3 years for 2018 age
             ggplot(aes(age)) +
               geom_histogram(binwidth = 0.5) +
               xlab("Age") +
               ylab("# of Injuries") +
               ggtitle("# of Injuries by Age in 2018") +
               scale_x_continuous(breaks = seq(0, 50, 1))
```

&nbsp;

## Try side by side bars for `age`
```{r}
players %>% ggplot(aes(age, fill = injury)) +
              geom_histogram(binwidth = 0.5, position = "dodge") +
              xlab("Age") +
              ylab("# of Injuries") +
              ggtitle("# of Injuries by Age in 2018") +
              scale_x_continuous(breaks = seq(0, 50, 1)) +
              scale_fill_manual(name = "Injury", 
                                guide = guide_legend(reverse=TRUE), values = c("#619CFF", "#F8766D"))
  
```

&nbsp;

## Try scaling by number of players in each age group
```{r}
age_group_size = players %>% group_by(age) %>% count() # get size of each age group

injured_age_group_size = players %>% # get size of age group for injured players only
                          filter(injury == 1) %>% 
                          group_by(age) %>% 
                          count()

# Some age groups have no injuries, so the vector lengths differ
group_size = age_group_size %>% filter(age %in% injured_age_group_size$age) %>% .$n

injured_age_group_size$scaled_n = injured_age_group_size$n / group_size # Scale by group size
head(injured_age_group_size)

injured_age_group_size %>% ggplot(aes(age, scaled_n)) +
                             geom_col() +
                             xlab("Age") +
                             ylab("Percentage") +
                             ggtitle("Percentage of Players Injured by Age Group") +
                             scale_x_continuous(breaks = seq(0, 50, 1)) +
                             scale_fill_manual(name = "Injury", 
                               guide = guide_legend(reverse=TRUE), values = c("#619CFF", "#F8766D"))
  
```

&nbsp;

### Logistic regression (model only; check for significant coefficients)

```{r}
players = players %>% mutate(position_id = relevel(position_id, ref = "TE"))

logi_fit = glm(data = players, injury ~ position_id + bmi + age, family = binomial())
pander(summary(logi_fit))

```

&nbsp;

### The older players could be skewing the results! The odds of getting injured for players above 40 is very high, mainly because there are very players who play at or above this age.

&nbsp;

### Let's remove the players above 40 y/o and see if `age` is still significant

```{r}
logi_fit2 = glm(data = players %>% filter(age < 40), injury ~ position_id + bmi + age, family = binomial())
pander(summary(logi_fit2))
```

&nbsp;

### Let's try Quadratic Age, too
```{r}
players = players %>% mutate(age_sq = age^2)

logi_fit3 = glm(data = players %>% filter(age < 40), injury ~ position_id + bmi + age + age_sq, family = binomial())
pander(summary(logi_fit3))

```

&nbsp;

# Machine Learning and Prediction

&nbsp;

### Create training and test set

```{r}
set.seed(1)

x <- stratified(players, "injury", 0.7, keep.rownames = TRUE)
train_set <- x %>% dplyr::select(-rn)
train_index <- as.numeric(x$rn)
test_set <- players[-train_index,]

dim(train_set)
dim(test_set)
```

&nbsp;

#### NOTE: Accuracy improved after removing `bmi` as a predictor

### Logistic regression (using `position_id` and `age` as features)

```{r, logistic regression}
logi_fit = glm(data = train_set, injury ~ position_id + age + age_sq, family = binomial())

p_hat_logit = predict(logi_fit, newdata = test_set, type = "response") # get predicted probabilities

y_hat_logit <- as.factor(ifelse(p_hat_logit > 0.5, 1, 0)) # set threshold of 0.5

confusionMatrix(data = y_hat_logit, 
                reference = test_set[["injury"]], positive = "1") # generate confusion matrix

```


&nbsp;



&nbsp;

### k-Nearest Neighbors

#### Use 2-fold cross-validation to find optimal `k` (achieves the highest accuracy for 0.5 cut-off)
```{r, eval=F}
set.seed(1)
control <- trainControl(method = 'cv', number = 2, p = .5) # cut-off of 0.5

players2 <- mutate(players, label = injury) %>%
  select(label, position_id, age)

res <- train(label ~ .,
             data = players2,
             method = "knn",
             trControl = control,
             tuneLength = 1, # How fine a mesh to go on grid
             tuneGrid = data.frame(k = seq(3, 151, 2)),
             metric = "Accuracy")

res$bestTune # best choice of 'k' is k = 131
plot(res)
```

```{r kNN, eval=F}
knn_fit = knn3(data = train_set, injury ~ position_id + age, k = 131) # fit kNN using optimal k = 131

f_hat_knn = predict(knn_fit, newdata = test_set)[ , 2] # get probability for injury

y_hat_knn = as.factor(ifelse(f_hat_knn > 0.5, 1, 0))

confusionMatrix(data = y_hat_knn, 
                reference = test_set[["injury"]], positive = "1") # generate confusion matrix

```

&nbsp;

### Random Forest

```{r Random Forest, eval=F}
rf_fit = randomForest(injury ~ position_id + age, 
                      data = players[train_index, ]) # fit random forest using training set

rf_fit

p_hat_rf = predict(rf_fit, newdata = test_set, type = "prob")[,2] # get predicted probabilities

y_hat_rf = as.factor(ifelse(p_hat_rf > 0.5, 1, 0)) # use 0.5 cutoff to get estimates

confusionMatrix(data = y_hat_rf, 
                reference = test_set[["injury"]], positive = "1") # generate confusion matrix

```

&nbsp;

&nbsp;

```{r, message=FALSE, eval=F}
roc_logi = roc(test_set[["injury"]], p_hat_logit) # ROC curve creation
roc_knn = roc(test_set[["injury"]], f_hat_knn)
roc_rf = roc(test_set[["injury"]], p_hat_rf)

ggroc(list("Logistic Regression" = roc_logi, "kNN, k = 11" = roc_knn, "Random Forest" = roc_rf)) +
  theme(legend.title = element_blank()) +
  geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), color = "black", linetype = "dashed") +
  xlab("Sensitivity") +
  ylab("Specificity") 

```


```{r, eval=F}
auc(roc_logi) # calculate AUC for each ROC curve
auc(roc_knn)
auc(roc_rf)
```

&nbsp;
