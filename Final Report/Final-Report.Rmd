---
title: "BST 260 Final Report"
author: "Dan Nolte"
date: "11/23/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### I) Overview and Motivation

We are a team of athletes and sports lovers, so we were interested in using data to research a problem in the world of professional sports. We decided to examine NFL injuries since particular injuries are common in football at the professional level, and their incidence and severity play a large role in determining the players’ comeback to play and a team’s success. Injuries don’t occur at random; we’d like to deduce some patterns underlying injury incidence to better understand the risks involved for players and teams.

In particular, we would like to examine which positions are most at risk for injuries, which injuries are most common, which teams have the most injuries (and if these teams are consistently the same each year), and whether injury incidence has evolved over time (and in particular, if concussion rates have decreased following the introduction of new helment technology in 2017). 

### II) Related Work

What inspired us most was a conversation we all had about the severity and even controversial topic of helmet protection/concussions in the NFL. We wondered if head injuries were the most common injuries among NFL players and if concussion injuries decreased once new rules and technology were introduced in 2017. From there, we considered other related topics pertaining to NFL injuries. 

We discovered that, unsurprisingly, we were not the first people to ask these questions. We came across a useful resource call [pro-football-reference.com](www.pro-football-reference.com) which compiled rosters and injuries for all NFL teams dating back to 2008, and included downloadable CSVs of this data for ease of analysis. We found that there is in fact a [Kaggle competition](https://www.kaggle.com/jaseziv83/an-analysis-of-nfl-injuries/report) which investigates the relationship between playing surface (synthetic turf vs. natural turf) and injury performance. We also discovered several independent analyses on this topic, including [one on the topic of concussions](https://www.edgewortheconomics.com/experience-06-23-2011-nfl-players-injury-analysis) from a consulting firm,[one on the relationship between weather conditions and injury incidence](https://www.datawithbliss.com/weather-data) conducted by a data scientist employed by the NFL, and [an academic research article](https://www.sciencedirect.com/science/article/pii/S2666061X21000808) examining the injury rate in the NFL in the 2020 NFL season, and claiming that it was higher than usual due to the lack of a pre-season because of COVID-19.    

These reports gave us confidence that was a precedence for studying these topics, and helped provide us a road map for asking plausible questions and sourcing data which would allow us to answer our research questions.  


### III) Initial Questions

We were initially interested in examining 7 questions, stated below: 

1) Which positions are most at-risk for injuries?
2) Which injuries are most common in the NFL?
3) Which teams have the most injuries, and are these teams consistently the same ones year over year?
4) How has injury incidence evolved over time in the NFL? 
5) Can we identify an association between weather conditions and injury risk?
6) What’s the distribution of injury duration? How many games must a player typically miss after being injured, and how does this vary by injury type?
7) What is the relationship between body type (e.g., height, weight, and BMI) and injury risk? What about age?  

We ultimately decided to only consider questions 1-4, for a few reasons. 

For question 5, we ran into a time constraint: because we built our own data for this project by web scraping pro-football-reference.com instead of using a pre-built dataset, finding and building the additional data that would be needed to answer our question about weather conditions would have cost time that was better spent answering questions 1-4 to the best of our abilities.  

We decided against studying questions 6 because as we began to work more closely with our dataset, we realized that the structure of our injury data source did not lend itself to answering our question about injury duration. It was not possible to reliably discern the length of time each athlete was injured due to one particular injury because, for example, it was common for athlete to have multiple injuries at once. Not to mention: we realized there was no way to know the duration of injuries that were incurred at the end of the season and which healed in the off-season.  

As for question 7, we realized that this question could be subsumed by other questions under consideration. For example, in our analysis of question 1 we ran a logistic regression predicting binary injury occurrence using the covariates under study in question 7.   

### IV) Data: Source, scraping method, cleanup, etc.

**1) Data source**
Our data source was [pro-football-reference.com](pro-football-reference.com). This website publishes a report of injuries for each NFL team, with a column for every game played by the team and a row for each player who had been injured during the season. 

**2) Web scraping method**

A webscraping algorithm was created which iterated across each year available on the website (2009-2021) and across each NFL team. The webscraping script read all information available from the table and saved it in an R object. 

**3) Data cleaning**

**a) Data shaping**

In order to conduct analyses on player injuries, injury tables were transformed into a table with one row per injured player per year. To do this, we first selected only the regular season games from each table to give equivalent estimates for teams who made it to the playoffs. We then counted the number of games a player was listed as injured (the sum of non-blank entries in the table) and the number of games a player was listed as not playing. In order to describe injuries, we concatenated all unique injury descriptions for a given player into one string. 


Additional player demographic data were provided by gridironai.com. Because this dataset had one row for every player for every week, duplicates were removed so that there was only one row per player per season. 

**b) Injury classification**

Once the data was scraped, there were issues with the free text in the injury column. In order to work with this data set to answer some of our primary questions, we needed to clean the data in such a way that the injuries could be easily modeled and analyzed. With so many injuries initially reported, as seen in the exploratory analysis below, we grouped the injuries into 8 main categories based on a part of the body. These included: Head, Shoulder, Upper Torso, Lower Torso, Arm, Hand, Leg and Foot. This way, the distribution of injuries was much easier to evaluate and draw conclusions from all while still keeping the injury data significant to each player. Once this decision was made, we went about the cleanup of the free text by first removing any special characters separating injuries from each other (mostly "\") and replacing them with a space. Many injuries were read like : "knee arm concussion head" as one large string. To deal with this issue we created a code and function that allowed each specific injury to be re-coded in its appropriate category. For example the above string would be recoded as "leg arm head head". Therefore we classified this player as having 1 leg injury, 1 arm injury and 2 head injuries. Once the injuries were re-coded, we used the mutate() function and created count columns for each of 8 body part injuries summing up how many of those injuries each player had. Once this was complete, we used the group_by() function and the summarise() function to obtain the the total counts of each body part injury. This way, we were able to move forward with answering some of our primary questions with a data set that was usable. 

### V) Exploratory Analysis: What visualizations did you use to look at your data in different ways? What are the different statistical methods you considered? Justify the decisions you made, and show any major changes to your ideas. How did you reach these conclusions?
[TODO: We need to have consistent style for charts. I vote using theme_economist() from the ggthemes library] 

[TODO: We create the same datasets multiple times in each of our analyses, we do not want to include this code in the Rmd file itself, and we definitely don't want to include it multiple times. We should 1) identify the datasets that we need to generate the charts below, 2) create and save these datasets in the Data folder as CSVs, 3) just refer to these datasets here for graphing results] 

We conducted exploratory data analysis on each of our 4 questions of interest separately. Below we will describe initial analysis and results for each question. 

##### Question 1: Which positions are most at-risk for injuries?
```{r, include=F}
library(caret)
library(e1071)
library(gam)
library(ggthemes)
library(lubridate)
library(magrittr)
library(pander)
library(pROC)
library(pscl)
library(randomForest)
library(rpart)
library(splitstackshape)
library(tidyverse)
library(dplyr)
theme_set(theme_economist())
options(digits = 3)
theme_update(plot.title = element_text(hjust = 0.5))
```

```{r, echo=F}
injuries = read.csv("../Data/data_for_plots/Q1/injury_dat_q1.csv", stringsAsFactors = T) %>% 
  mutate(injury = factor(injury))

players = read.csv("../Data/data_for_plots/Q1/players_dat_q1.csv", stringsAsFactors = T) %>% mutate(injury = factor(injury))
```

To answer this question, we used the web scraped injury and player demographic data. We merged these datasets and created factors where appropriate. We then created a binary injury variable that had a value of “1” for injured players and a “0” for non-injured players. The summary statistics below were computed for each position over all the years:

```{r, echo=F}
# set up table
number_injury = injuries %>% 
  group_by(position_id, year) %>% 
  count()

number_injury %>% group_by(position_id) %>% 
  summarise(mean = mean(n), 
            sd = sd(n), 
            Q1 = quantile(n, probs = 0.25),
            median = median(n),
            Q3 = quantile(n, probs = 0.75)
  ) %>% 
  pander
```                                                   

We could interpret the mean value for defensive players (DEF) by stating that about 512 DEF players are injured per season. Although informative, this approach does not provide insight into the number of injuries that a defensive player could expect to incur in a given season. To obtain this information, we created a new variable that counts the total number of injuries for each player. We then grouped by position and year to find the total number of injuries for each position. This value was then divided by the number of players and then the number of seasons to produce the average injuries per player per year. These results as well as other summary statistics are presented below.

```{r, echo=F}

# total injuries per player per year
exp_injuries <- players %>% 
  filter(!is.na(total_injuries)) %>% # remove players with no injury (NA's)
  group_by(position_id) %>% 
  summarise(avg_total_injuries = sum(total_injuries)/n(),
            SD = sd(total_injuries), 
            Q1 = quantile(total_injuries, probs = 0.25),
            Median = median(total_injuries),
            Q3 = quantile(total_injuries, probs = 0.75),
            Min = min(total_injuries),
            Max = max(total_injuries)
  )

exp_injuries %>% pander
```

Now, we can state the expected number of injuries for a DEF player is about 2 per season, or that a quarterback (QB) can also expect to get injured about 2 times per season.\

In addition to total injury counts over the total 2009-2021 period, we are also concerned with the evolution of these counts over time. We chart this below.

```{r, echo=F, message=F}
players %>% group_by(position_id, year) %>% 
  summarise(total = sum(total_injuries, na.rm = T)) %>% 
  ggplot(aes(year, total, color = position_id)) +
  geom_line() +
  xlab("Year") +
  ylab("Total Injuries (log scale)") +
  scale_y_log10() +
  ggtitle("Total Injuries by Position (2009 - Present)") +
  scale_x_continuous(breaks = seq(2008, 2020, by = 2)) +
  scale_color_discrete(name = "Position", labels = c("Defense", "Kicker", "Offensive Line", "Punter", 
                                                     "Quarterback", "Running Back", "Tight End", "Wide Receiver")) 
  
```

When viewing the plot, it is important to note that some positions have more players on the field than others. For example, there are eleven defensive players on at a given time but only one quarterback. This suggests that scaling should be performed to account for the different group sizes. Scaling by the number of players in each position would essentially be the average number of injuries per player per position. The plot of these averages over time is presented below:

```{r, echo=F, message=F}
# code for plot over time
exp_injuries_byYear <- players %>% 
  filter(!is.na(total_injuries)) %>% # remove players with no injury (NA's)
  group_by(position_id, year) %>% 
  summarise(avg_total_injuries = sum(total_injuries)/n())# trying to divide by number of players to get avg. for each player
# plot
exp_injuries_byYear %>%
  ggplot(aes(x = year, y = avg_total_injuries, color = position_id)) +
  geom_line() +
  ggtitle("Average Number of Injuries per Season among Injured Players") +
  ylim(0.7, 2.3) +
  xlab("Season") +
  ylab("Average Total Injuries") +
  scale_x_continuous(breaks = seq(2008, 2020, by = 2)) +
  scale_color_discrete(name = "Position", labels = c("Defense", "Kicker", "Offensive Line", "Punter", 
                                                     "Quarterback", "Running Back", "Tight End", "Wide Receiver")) 
```

Another important part of our analysis was checking for missing data. The table below shows that we had a small number of missing measurements for player height/weight/bmi. These values were removed prior to the analyses.

```{r, echo=F}
apply(players %>% 
        dplyr::select(injury, position_id, height_inches, weight_pounds, game_starter, age, bmi, year), 
      2, function(x) sum(is.na(x))) %>% pander

# remove the 13 people with missing height/weight (much less than 5% of each column)
players <- players %>%
  drop_na(height_inches)
```

After completing our initial EDA, we turned our attention to the classification task of predicting whether a player will be injured in a given season given their position, as well as other player information (e.g., height, weight, age, team). And, where possible, we sought to interpret odds ratios explaining the relationship between player position and injury risk. The three main classification algorithms we explored were logistic regression, k-Nearest Neighbors (kNN), and Random Forest. These methods were selected due to the categorical nature of our outcome (injured or not), and because of the varying degrees of flexibility afforded by these approaches. We first proceed with exploratory analysis to assess the suitability of logistic regression for this task. The initial screening below considers p-values to be significant if they fall below the standard significance level of 0.05.

```{r, echo=F}
players = players %>% mutate(position_id = relevel(position_id, ref = "TE"))

logi_fit = glm(data = players, injury ~ position_id + bmi + age, family = binomial())
pander(summary(logi_fit))

```

From here, we opted to perform forward selection as a more systematic way of finding good features for the model. The process of forward selection begins by regressing the outcome variable on just the intercept, and then subsequently adds covariates to the model based on which obtains the lowest AIC value. The final results of this process appear below:

```{r, echo=F}
# baseline logistic regression model (intercept only)
logi_fit_all <- glm(data = players, injury ~ 1, family = binomial())
summary(logi_fit_all)

# forward selection
logi_step_fit <- logi_fit_all %>% 
  step(direction = "forward", data = players, 
       scope = (~ position_id + height_inches + weight_pounds + game_starter + 
                  age + I(age^2) + bmi + year), trace = 0)
summary(logi_step_fit)
```

We see that Game starter (yes/no), year, position, age, age_squared, and weight (lbs) were the most useful predictors. Age squared was added as a potential predictor because of the possibility that age and injury status may have a quadratic relationship, where the risk of injury increases as players get older, but then decreases after a certain age since fewer people play football beyond 40. After completing the initial variable screening, we began fitting the machine learning models. The data was divided for the training and test sets, with the former receiving 70% of the data and the latter receiving the remaining 30%. The Confusion Matrix, Accuracy, Sensitivity, Specificifify of the models are presented below. In addition, the `k` parameter for kNN was found by two-fold cross-validation. We chose `k = 21` as this is the point where the accuracy began to level off.

```{r, echo=F, include=F}
set.seed(1)

x <- stratified(players, "injury", 0.7, keep.rownames = TRUE)
train_set <- x %>% dplyr::select(-rn)
train_index <- as.numeric(x$rn)
test_set <- players[-train_index,]

dim(train_set)
dim(test_set)
```

### Logistic Regression

```{r, logistic regression, echo=F}
logi_fit = glm(data = train_set, family = binomial(),
               injury ~ position_id + weight_pounds + game_starter + age + I(age^2) + year)

p_hat_logit = predict(logi_fit, newdata = test_set, type = "response") # get predicted probabilities

y_hat_logit <- as.factor(ifelse(p_hat_logit > 0.5, 1, 0)) # set threshold of 0.5

confusionMatrix(data = y_hat_logit, 
                reference = test_set[["injury"]], positive = "1") # generate confusion matrix

```

### k-Nearest Neighbors

```{r, eval=F, echo=F}
# find optimal k
set.seed(1)

control <- trainControl(method = 'cv', number = 2, p = .5) # cut-off of 0.5

players2 <- mutate(players, label = injury) %>%
  dplyr::select(label, position_id, weight_pounds, game_starter, age, year)

res <- train(label ~ .,
             data = players2,
             method = "knn",
             trControl = control,
             tuneLength = 1, # How fine a mesh to go on grid
             tuneGrid = data.frame(k = seq(3, 71, 2)),
             metric = "Accuracy")

res$bestTune # best choice of 'k'
plot(res)
```

```{r kNN, echo=F}
knn_fit = knn3(data = train_set, injury ~ position_id + age + I(age^2) + game_starter + 
                 weight_pounds + year, 
               k = 21) # fit kNN using optimal

f_hat_knn = predict(knn_fit, newdata = test_set)[ , 2] # get probability for injury

y_hat_knn = as.factor(ifelse(f_hat_knn > 0.5, 1, 0))

confusionMatrix(data = y_hat_knn, 
                reference = test_set$injury, positive = "1") # generate confusion matrix

```

### Random Forest

```{r Random Forest, echo=F}
rf_fit = randomForest(injury ~ position_id + age + I(age^2) + game_starter + weight_pounds + year,
                      data = train_set) # fit random forest using training set

rf_fit

p_hat_rf = predict(rf_fit, newdata = test_set, type = "prob")[,2] # get predicted probabilities

y_hat_rf = as.factor(ifelse(p_hat_rf > 0.5, 1, 0)) # use 0.5 cutoff to get estimates

confusionMatrix(data = y_hat_rf, 
                reference = test_set[["injury"]], positive = "1") # generate confusion matrix

```

From the results, we see that the Random Forest obtained the highest accuracy of 0.639, with the logistic regression and kNN receiving accuracies of 0.638 and 0.613, respectively. The ROC curves and corresponding AUC values are presented below.

```{r, message=FALSE, echo=F}
roc_logi = roc(test_set[["injury"]], p_hat_logit) # ROC curve creation
roc_knn = roc(test_set[["injury"]], f_hat_knn)
roc_rf = roc(test_set[["injury"]], p_hat_rf)

ggroc(list("Logistic Regression" = roc_logi, "kNN, k = 71" = roc_knn, "Random Forest" = roc_rf)) +
  theme(legend.title = element_blank()) +
  geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), color = "black", linetype = "dashed") +
  ggtitle("ROC Curves") +
  xlab("Specificity") +
  ylab("Sensitivity") 
```

```{r}
auc(roc_logi) # calculate AUC for each ROC curve
auc(roc_knn)
auc(roc_rf)
```

We now will compare the three models based on Accuracy, AUC, and Sensitivity/Specificity:\

**Accuracy**\

* logistic regression: 0.638
* kNN: 0.58
* random forest: 0.636

We see that the logistic regression model has the highest accuracy.\

**AUC** \

* logistic regression: 0.701
* kNN: 0.607
* random forest: 0.691

We also see that the logistic regression model has the highest AUC. Now, since it is clear that kNN is the poorest performing model, we will only consider the logistic regression and random forest going forward.\

**Logistic Regression:**\ 

* Sensitivity: 0.675          
* Specificity: 0.600   

**Random Forest:**\

* Sensitivity: 0.632         
* Specificity: 0.640

The random forest is slightly more balanced in terms of sensitivity/specificity. However, the logistic regression attains a higher sensitivity.\

All things considered, the logistic regression has the highest accuracy and the highest AUC of all 3 models. It also provides us with clearly interpretable odds ratios for the risk of injury. For these reasons, we will choose logistic regression as the best model for our situation.

##### Question 2: Which injuries are most common in the NFL?

We are also interested in understanding which injuries are most common in the NFL; we begin by simply charting the distribution of injuries, using the very granular injury type classifications available from our data source. 

```{r, echo=FALSE, message = FALSE, fig.width = 10}
# Load data
injuries <- read.csv("../Data/all_injuries_clean.csv")

# Load count distribution function
source("../EDA/Question2/EDA1Function.R")

# Create injury count data set
injury_count <- generate_dataset(injuries)
```

```{r, echo=FALSE, message=FALSE, fig.width=10, fig.height=10}
library(ggplot2)
library(ggthemes)

injury_count %>%
  mutate(injurytype = reorder_within(injurytype,count, bodypart)) %>%
  ggplot(aes(y=injurytype, x=count)) +
  geom_col()+
  scale_y_reordered() +
  geom_text(aes(label = count), position = position_dodge(width = 0.9), vjust = .4, hjust = -.1, fontface = 'bold') +
  xlab("Count") +
  ylab("Injury Type") + 
  ggtitle("Distribution of Specific Injury Types") +
  theme_economist() +
  theme(
    axis.title.x = element_text(size = 14, vjust = -3),
    axis.title.y = element_text(size = 14, vjust = 3),
    title = element_text(size = 18),
    plot.title = element_text(hjust = 0.5, vjust = 2.5)
  )


```

We see here that looking at each specific injury does give us information, but after about the first half of the injury list, the graph is not very impactful. We do conclude however from this graph that knee, ankle and hamstring injuries were the most common injury in NFL football players. After this initial EDA, injuries were group into more general body part injuries as head, shoulder, upper torso, lower torso, arm, hand, leg and foot. This way we were able to analyze the distribution of general injuries more clearly and come to a meaningful conclusion. This can be seen in the RShiny app provided in the EDA files and on the website. 

##### Question 3: Which teams have the most injuries, and are these teams consistently the same ones year over year?

```{r, echo=FALSE, message=FALSE}
library(tidyverse)
library(eeptools)
library(vcd)
library(ggthemes)
library(lubridate)
```

```{r, echo=FALSE, message = FALSE}
# Load Data
load("../Data/data_for_plots/injuries_by_team.Rdata")
load("../Data/data_for_plots/injuries_by_team_with_year_summary.Rdata")
```

We first consider the total injuries per year over the entire 2009-2021 period, as well as the max injuries that a team had in a single season over this period. 


```{r, echo =FALSE}
# Plot 1
p1 = ggplot(data = injuries_by_team, aes(x = total_injuries, y = reorder(full_team, total_injuries))) +
  geom_col() + 
  theme_economist() + 
  xlab("Total Injuries") +
  ylab(element_blank()) +
  ggtitle("Total Injuries by Team, 2009-2020")
p1
```

```{r, echo=FALSE}
# Plot 2
p2 = ggplot(data = injuries_by_team, aes(x = max_injuries, y = reorder(full_team, max_injuries))) +
  geom_col() + 
  theme_economist() + 
  xlab("Total Injuries") +
  ylab(element_blank()) +
  ggtitle("Max Injuries in a Single Season, 2009-2020")
p2
```


It is clear that the Houston Texans have the most total injuries over this period, as well as the maximum injuries. Let's take a look at the distribution of injury counts over each year in the 2009-2021 period, as well as the distirbution of injury counts as shown in a boxplot.   


```{r, echo=FALSE}
# Plot 3
p3 = ggplot(data = injuries_by_team_year_with_summary, aes(x = all_injuries, y = reorder(full_team, median_injuries))) +
  geom_boxplot() + 
  theme_economist() + 
  xlab("Injuries Per Year") +
  ylab(element_blank()) +
  ggtitle("Injuries Per Year (2009-2020), by Team")
p3
```

```{r, echo=FALSE}
# Plot 4
p4 = ggplot(data = injuries_by_team_year_with_summary, aes(x = year, y = full_team)) +
  geom_tile(aes(fill = all_injuries), color = "white") + 
  scale_fill_distiller(palette = "YlGnBu", direction = 1) +
  xlab("Year") +
  ylab(element_blank()) +
  ggtitle("Injuries by Team") +
  theme_economist() +
  theme(legend.position = "right") + 
  labs(fill = "Injuries")
p4
```

From the final chart it appears that the Texans' large number of injuries seem to be concentrated in the 2011-2013 range, after which their injury rates appear to be on par with the rest of the league. 

##### Question 4: How has injury incidence evolved over time in the NFL?

Willow Include: Initial EDA with no cleanup, new EDA with cleanup (for all players), EDA based on Offense or Defense, EDA based on age, EDA based on year

### VI) Final Analysis: What did you learn about the data? How did you answer the questions? How can you justify your answers? Note that 1 type of analysis per team member is required. A Shiny app counts as a type of analysis.
[TODO: We need to decide what qualifies as "exploratory analysis" and what qualifies as "final analysis" for each question.]

I'm thinking everyone can put down what they discovered for their analysis here 




